{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21a06b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/dangnguyen/weak-to-strong/wts_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/data/dangnguyen/weak-to-strong/wts_env/lib/python3.8/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizerFast, AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import Dataset, load_dataset\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e69b1197",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path = '/data/dangnguyen/cache/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52b8eeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████| 34/34 [00:04<00:00,  7.11it/s]\n",
      "/data/dangnguyen/weak-to-strong/wts_env/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/data/dangnguyen/weak-to-strong/wts_env/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/data/dangnguyen/weak-to-strong/wts_env/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/data/dangnguyen/weak-to-strong/wts_env/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = 'sharpbai/Llama-2-7b-chat'\n",
    "tokenizer = LlamaTokenizerFast.from_pretrained(model_name, cache_dir=cache_path)\n",
    "model = LlamaForCausalLM.from_pretrained(model_name, cache_dir=cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7501dd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, cache_dir=cache_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67132c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd8529a",
   "metadata": {},
   "source": [
    "### DAIR-AI Emotion dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53be744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_label(label):\n",
    "    if label == 0:\n",
    "        return 'sadness'\n",
    "    elif label == 1:\n",
    "        return 'joy'\n",
    "    elif label == 2:\n",
    "        return 'love'\n",
    "    elif label == 3:\n",
    "        return 'anger'\n",
    "    elif label == 4:\n",
    "        return 'fear'\n",
    "    elif label == 5:\n",
    "        return 'surprise'\n",
    "    else:\n",
    "        return 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194b2b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('dair-ai/emotion', split='test')\n",
    "\n",
    "# Filtering for obvious samples\n",
    "keywords = ['sad', 'joy', 'love', 'anger', 'fear', 'surprise']\n",
    "dataset_clean = {\n",
    "    'text': [],\n",
    "    'label': [],\n",
    "}\n",
    "\n",
    "for data in dataset:\n",
    "    keep = True\n",
    "    for kw in keywords:\n",
    "        if kw in data['text']:\n",
    "            keep = False\n",
    "            break\n",
    "    if keep:\n",
    "        dataset_clean['text'].append(data['text'])\n",
    "        dataset_clean['label'].append(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131e3852",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_eng = list(map(map_label, dataset_clean['label']))\n",
    "dataset_clean['label_text'] = labels_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0f9cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_torch = Dataset.from_dict(dataset_clean)\n",
    "dataset_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abebd00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.choice(dataset_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff066e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = open('/data/dangnguyen/weak-to-strong/prompts/emotion_fewshot.txt').read()\n",
    "template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a633fe",
   "metadata": {},
   "source": [
    "### Tweet Sentiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43ca7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('mteb/tweet_sentiment_extraction', split='test')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ee28e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_torch = Dataset.from_dict(dataset[:2000])\n",
    "dataset_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3597ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.choice(dataset_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ad1e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = open('/data/dangnguyen/weak-to-strong/prompts/tweet_sentiment_fewshot.txt').read()\n",
    "template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aea43e7",
   "metadata": {},
   "source": [
    "### Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241223ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "for sample in tqdm(dataset_torch):\n",
    "    prompt = template.format(input=sample['text'])\n",
    "    input_ids = tokenizer(prompt, return_tensors='pt').to('cuda')\n",
    "    max_len = input_ids['input_ids'].shape[1]\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(input_ids['input_ids'], max_length=max_len+5)\n",
    "    output = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "    outputs.append(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5232be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa15991",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_labels = list(map(lambda x: x.split('>\\n\\nAnswer:\\n')[1].lower().strip(), outputs))\n",
    "output_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76c40c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# control\n",
    "labels = ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n",
    "control_labels = [random.choice(labels) for _ in range(2000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822bba05",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for pred, gt in zip(output_labels, dataset_torch['label_text']):\n",
    "    if pred == gt:\n",
    "        correct += 1\n",
    "        \n",
    "accuracy = correct / len(output_labels)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5facf07",
   "metadata": {},
   "source": [
    "### Synthetic datasets: hierarchical equality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebd9efb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the data\n",
    "\n",
    "def get_accuracy(preds, labels):\n",
    "    num_correct = 0\n",
    "    for pred, label in zip(preds, labels):\n",
    "        if pred == label:\n",
    "            num_correct += 1\n",
    "    return num_correct / len(labels)\n",
    "\n",
    "def get_equiv_rel_data(n_samples=1000, start=0, end=99):\n",
    "    def sample_one():\n",
    "        label = random.choice(['Yes', 'No'])\n",
    "        if label == 'Yes':\n",
    "            a, b = sample_equiv(start, end)\n",
    "        else:\n",
    "            a, b = sample_not_equiv(start, end)\n",
    "        return (a, b, label)\n",
    "    \n",
    "    sampled_data = [sample_one() for _ in range(n_samples)]\n",
    "    sampled_input = [\"{} {}\".format(a, b) for a, b, _ in sampled_data]\n",
    "    sampled_label = [label for _, _, label in sampled_data]\n",
    "    return (sampled_input, sampled_label)\n",
    "\n",
    "def get_hierarch_data(n_samples=1000):\n",
    "    def sample_one():\n",
    "        values = ['Yes', 'No']\n",
    "        var1 = random.choice(values)\n",
    "        var2 = random.choice(values)\n",
    "        if var1 == var2:\n",
    "            label = 'Yes'\n",
    "        else:\n",
    "            label = 'No'\n",
    "            \n",
    "        if var1 == 'Yes':\n",
    "            a, c = sample_equiv()\n",
    "        else:\n",
    "            a, c = sample_not_equiv()\n",
    "        if var2 == 'Yes':\n",
    "            b, d = sample_equiv()\n",
    "        else:\n",
    "            b, d = sample_not_equiv()\n",
    "        return (a, b, c, d, label)\n",
    "    \n",
    "    sampled_data = [sample_one() for _ in range(n_samples)]\n",
    "    sampled_input = [\"({},{}) ({},{})\".format(a, b, c, d) \\\n",
    "                     for a, b, c, d, _ in sampled_data]\n",
    "    sampled_label = [label for _, _, _, _, label in sampled_data]\n",
    "    return (sampled_input, sampled_label)\n",
    "\n",
    "def sample_equiv(start=0, end=99):\n",
    "    b = random.randint(start, end-3)\n",
    "    a = b + 3\n",
    "    return a, b\n",
    "\n",
    "def sample_not_equiv(start=0, end=99):\n",
    "    a = random.randint(start, end)\n",
    "    b = random.randint(start, end)\n",
    "    while a - b == 3:\n",
    "        b = random.randint(start, end)\n",
    "    return a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c741f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_size = 1000\n",
    "# raw_data = get_equiv_rel_data(total_data_size, start=50, end=99)\n",
    "raw_data = get_hierarch_data(total_data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ea76fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pos = 0\n",
    "for label in raw_data[1]:\n",
    "    if label == 'Yes':\n",
    "        num_pos += 1\n",
    "num_pos / len(raw_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f6498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = open('/data/dangnguyen/weak-to-strong/weak-to-strong/prompts/hierarchical_equiv_zeroshot.txt').read()\n",
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ff1b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [template.format(INPUT=data) for data in raw_data[0]]\n",
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d5ddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./datasets/hierarchical_equivalence/train.csv', 'w') as fw:\n",
    "    fw.write('input,label\\n')\n",
    "    for prompt, label in zip(prompts, raw_data[1]):\n",
    "        prompt_csv = prompt.replace('\\n', '\\\\n')\n",
    "        fw.write('\"{}\",{}\\n'.format(prompt_csv, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "386a56a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input', 'label'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input', 'label'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset = load_dataset('dangnguyen0420/equivalence_relation')\n",
    "dataset = load_dataset('dangnguyen0420/hierarchical_equivalence')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd4bb710",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset['train'], batch_size=16)\n",
    "test_dataloader = DataLoader(dataset['test'], batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cb061a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [02:38<00:00,  2.52s/it]\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    epoch_iterator = tqdm(train_dataloader)\n",
    "    for _, inputs in enumerate(epoch_iterator):\n",
    "        input_ids = tokenizer(inputs['input'], padding=True, return_tensors='pt').to('cuda')\n",
    "        output_ids = model(**input_ids)\n",
    "        \n",
    "        pred_ids = output_ids.logits[:, -1, :].argmax(dim=-1)\n",
    "        preds = tokenizer.batch_decode(pred_ids)\n",
    "        \n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(inputs['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46ef8f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.498"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds = reduce(lambda x, y: x + y, all_preds)\n",
    "all_labels = reduce(lambda x, y: x + y, all_labels)\n",
    "\n",
    "test_acc = get_accuracy(all_preds, all_labels)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4299aa13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b98a429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00df488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13749ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fe67bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e118a3e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864c3b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411a1698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d92c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ee2610",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wts_env",
   "language": "python",
   "name": "wts_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
